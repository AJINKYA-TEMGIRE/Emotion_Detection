1. Created Repository on github
2. Cookie Cutter
3. Deleted unnecessary files
4. src/models = src/model
5. Git remote and push
6. We have to download the mlflow and dagshub so make python environment and activate it.
7. Install mlflow and dagshub
8. Test the Mlflow and Dagshub  
9. Push the existing code to repo (add env folder to .gitignore)
10. Plan the experiments (This is just a case study to use all the concepts, so will not be focusing much on accuracy)
11. After each experiment push the code to github 
12. dvc init
13. add dvc remote  (echo %TEMP%) (dvc add remote -d myremote C:\Users\Dell\AppData\Local\Temp)
14. Set data ingestion (params , dvc yaml)  (test_size)
15. Then all other steps (Each time dvc repro)
16. At last also write to register the model.    (You can make the staging to production on UI)
17. Generate the requirements.txt
18. Setting up the CI 
    1. DVC
    2. Test (get model , signature , evaluation)
    3. Get to the production
    4. test flask app   (with the hold out test set)
19. Docker file for only flask app with its dependencies like vectorizer
    (pip install pipreqs)
    (go to flaskapp and then pipreqs . --force)
    (docker run -p 8888:5000 -e CI:   emotion)
20. Run one time and then push it to docker hub
21. This is the development server, do not use in production
22. So use the gunicorn
23. Build again the image with version and again push (But this building and pushing should be through the CI)



